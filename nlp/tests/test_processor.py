from core.processor import preprocesar_texto


def test_tokenizacion_basica():
    texto = "Me siento cansado y sin energÃ­a Ãºltimamente."
    resultado = preprocesar_texto(texto)

    print("\nğŸ”¹ Verificando tokenizaciÃ³n y lematizaciÃ³n bÃ¡sicas...")

    assert isinstance(
        resultado, list), "[âŒ ERROR] El resultado no es una lista."

    assert "cansado" in resultado, "[âŒ ERROR] Token 'cansado' no encontrado."
    assert "energÃ­a" in resultado, "[âŒ ERROR] Token 'energÃ­a' no encontrado."
    assert "sentir" in resultado, "[âŒ ERROR] Token 'sentir' (lematizaciÃ³n de 'siento') no encontrado."

    print("âœ… TokenizaciÃ³n y lematizaciÃ³n correctas.")


def test_eliminacion_stopwords():
    texto = "Estoy muy pero muy feliz de estar aquÃ­"
    resultado = preprocesar_texto(texto)

    print("\nğŸ”¹ Verificando eliminaciÃ³n de stopwords...")

    assert "feliz" in resultado, "[âŒ ERROR] 'feliz' deberÃ­a permanecer."
    assert "muy" not in resultado, "[âŒ ERROR] 'muy' no deberÃ­a aparecer."
    assert "pero" not in resultado, "[âŒ ERROR] 'pero' no deberÃ­a aparecer."

    print("âœ… EliminaciÃ³n de stopwords correcta.")


# Ejecutar todos los tests si el archivo se corre directamente
if __name__ == "__main__":
    print("\n==============================================")
    print("ğŸš€ Iniciando Tests de Procesamiento de Texto (processor.py)")
    print("==============================================")

    test_tokenizacion_basica()
    test_eliminacion_stopwords()

    print("\nğŸ¯ Todos los tests de Procesador de Texto pasaron correctamente.\n")
